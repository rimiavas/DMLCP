{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with MNIST\n",
    "\n",
    "This notebook expects you to have previously trained the MNIST model and saved the resulting file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canvas Installation: Two Workflows\n",
    "\n",
    "### 1. Jupyter (locally)\n",
    "\n",
    "The recommended way is to clone the repo, which contains `canvas.py`. Make sure you have [pycairo](https://anaconda.org/conda-forge/pycairo) installed:\n",
    "\n",
    "```bash\n",
    "conda activate dmlap\n",
    "conda install -c conda-forge pycairo\n",
    "```\n",
    "\n",
    "### 2. Google Colab\n",
    "\n",
    "When using Google Colab you will need to use `pip` and install additional libraries (based on [this](https://github.com/pygobject/pycairo/issues/39#issuecomment-391830334)):\n",
    "\n",
    "```bash\n",
    "# WARNING!!!! Do NOT do this if you are running jupyter/python locally!!!\n",
    "!apt-get install libcairo2-dev libjpeg-dev libgif-dev\n",
    "!pip install pycairo\n",
    "```\n",
    "\n",
    "#### 2.1 Working with the repo in your drive\n",
    "\n",
    "Mount your drive and change to the correct directory:\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# change directory using the os module\n",
    "import os\n",
    "os.chdir('drive/My Drive/')\n",
    "os.listdir()             # shows the contents of the current dir, you can use chdir again after that\n",
    "# os.mkdir(\"DMLCP-2023\") # creating a directory\n",
    "# os.chdir(\"DMLCP-2023\") # moving to this directory\n",
    "# os.getcwd()            # printing the current directory\n",
    "```\n",
    "\n",
    "See [this notebook](https://colab.research.google.com/notebooks/io.ipynb), and [Working With Files](https://realpython.com/working-with-files-in-python/) on Real Python.\n",
    "\n",
    "#### 2.2 Working on it as a standalone notebook\n",
    "\n",
    "Get the`canvas` module:\n",
    "\n",
    "```python\n",
    "!curl -O https://raw.githubusercontent.com/jchwenger/DMLCP/main/python/canvas.py\n",
    "```\n",
    "\n",
    "Download and unzip the necessary images with:\n",
    "\n",
    "```python\n",
    "!curl -O https://raw.githubusercontent.com/jchwenger/DMLCP/main/python/images/3.png\n",
    "!curl -O https://raw.githubusercontent.com/jchwenger/DMLCP/main/python/images/4.png\n",
    "!mkdir images\n",
    "!mv 3.png 4.png images\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import canvas\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Get cpu, gpu or mps device for training\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = [1,28,28]\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # [1, 28, 28] -> [1, 28*28]\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(INPUT_SHAPE[1] * INPUT_SHAPE[2], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "MODELS_DIR = pathlib.Path(\"models\")\n",
    "\n",
    "MODEL_NAME = \"dense_mnist\"\n",
    "\n",
    "MNIST_DIR = MODELS_DIR / MODEL_NAME\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(MNIST_DIR / f\"{MODEL_NAME}.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify an image of a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('images/3.png') # try also images/4.png\n",
    "\n",
    "transforms = tv.transforms.v2.Compose([  \n",
    "    tv.transforms.Grayscale(num_output_channels=1),\n",
    "    tv.transforms.Resize(size=(28,28), antialias=True),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "input = transforms(img)\n",
    "input = input.to(device)\n",
    "\n",
    "print(f\"Input shape: {input.shape}\")\n",
    "\n",
    "def predict(model, input): \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        probs = nn.Softmax(dim=-1)(model(input)).cpu().numpy()\n",
    "        return np.argmax(probs[0])\n",
    "        \n",
    "predicted = predict(model, input)\n",
    "canvas.show_image(img, title=f'Predicted number: {predicted}', cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two directions\n",
    "\n",
    "1. **disrupt**: try and find cases where the network fails to predict the images properly\n",
    "2. **generate**: come up with your own images and try to classify them! Combining the two, you can try to generate images that the network fails to classify!\n",
    "\n",
    "### Note: Dense vs ConvNet\n",
    "\n",
    "If you tried to train a ConvNet, you will notice that it tends to be more stable in its prediction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Disrupt\n",
    "\n",
    "Here we provide you with a canvas object that generates images with a number. You can see that a Dense net not always succeeds (and the ConvNet does)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random number between 0 and 9 (the max is excluded)\n",
    "number = np.random.randint(0, 10) \n",
    "c = canvas.Canvas(28, 28)\n",
    "c.background(0)\n",
    "c.fill(255)\n",
    "c.text_size(26)\n",
    "c.text([c.width/2, c.height/2 + 9], str(number), center=True)\n",
    "x = c.get_image_grayscale()\n",
    "\n",
    "# little things:\n",
    "# convert to float32, and convert \n",
    "print(x.shape, x.dtype)\n",
    "x = torch.tensor(x, dtype=torch.float32).view(INPUT_SHAPE).to(device)\n",
    "print(x.shape, x.dtype)\n",
    "\n",
    "predicted = predict(model, x)\n",
    "c.show(title=f'Predicted number: {predicted}', size=(512, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disruption, first idea: how about we invert the colours? We do that by adding: `1.0 - c.get_image_grayscale()` (our pixel values lie between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = np.random.randint(0, 10)\n",
    "c = canvas.Canvas(28, 28)\n",
    "c.background(255)\n",
    "c.fill(0)\n",
    "c.text_size(26)\n",
    "c.text([c.width/2, c.height/2 + 9], str(number), center=True)\n",
    "\n",
    "#Â test: rotation?\n",
    "# c.translate(c.width/2, c.height/2 + 7)\n",
    "# c.rotate(torch.rand(1).item() * 2 * math.pi) # random rotation from 0 to 2 pi\n",
    "# c.text([0, 0], str(number), center=True)\n",
    "\n",
    "x = 1.0 - c.get_image_grayscale() # Inverted (note: this array has already values in [0,1], no need to divide by 255)\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32).view(INPUT_SHAPE).to(device)\n",
    "\n",
    "predicted = predict(model, x)\n",
    "c.show(title=f'Predicted number: {predicted}', size=(512, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for exploration\n",
    "\n",
    "- Creatively disrupt the image, keeping it recognizable to a human, but causing the model to produce an incorrect prediction. You could add random dots, or patches, for instance. Or simply create an array of random numbers of the same size as the image and add it to the image.\n",
    "- Try to do this in steps, e.g. incrementally adding modifications to the image and observing when and how it stops being recongized by the model.\n",
    "- Briefly discuss the steps you are taking, taking advantage of the hybrid markdown/code format of the notebook.\n",
    "\n",
    "Make sure to display the images you are creaating!\n",
    "\n",
    "You may want to work with the `Canvas` object directly, using some tools demonstrated in the relevant notebook, in which case you should keep in mind that you are only producing grayscale images and that the images have size 28x28.\n",
    "\n",
    "Otherwise you might as well work by preparing images externally (e.g. by hand, or using p5js) and then loading these as we have seen earlier for the image of a four. If you take this approach, make sure you start from an image that is consistently recognizable to a human as a given number and correctly classified by the model as that same number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate\n",
    "\n",
    "Here is a simple example that looks like a `0`, and usually gets classified as one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = canvas.Canvas(28, 28)\n",
    "c.background(0)\n",
    "\n",
    "c.no_stroke()\n",
    "for t in np.linspace(1, 0.2, 5):\n",
    "    c.fill(255*t)\n",
    "    c.circle([c.width/2, c.height/2], 10*t)\n",
    "\n",
    "x = c.get_image_grayscale()\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32).view(INPUT_SHAPE).to(device)\n",
    "\n",
    "predicted = predict(model, x)\n",
    "c.show(title=f'Predicted number: {predicted}', size=(512, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This most interesting when not using the text function any more, but rather using the drawing abilities of canvas.\n",
    "\n",
    "Try different numbers!\n",
    "\n",
    "**Also**, try shapes that *really do not look like numbers* to us, and see what happens.\n",
    "\n",
    "As before, a ConvNet will probably perform better than a plain Dense net.\n",
    "\n",
    "### Note\n",
    "\n",
    "If you trained a net on FashionMNIST, you can do the same thing but with pieces of clothing! (The images must always be b&w, 28*28!)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "org": null,
  "vscode": {
   "interpreter": {
    "hash": "1c544d3133b9d8c6f36fca025551af31afa9ef134259e7064ad6be0c15e6401c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
